{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb2e176-f4ed-4cfe-89fd-0a1a22416bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "No GPU available, using the CPU instead\n"
     ]
    }
   ],
   "source": [
    "#im using CPU hehe\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "\n",
    "  print('there are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "  print('we will use the GPU: ', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "  print(\"No GPU available, using the CPU instead\")\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9ba51-5a01-49e4-93c0-893703de3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do pip install transformers if haven't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b72b2d-35de-4b24-83f1-61533312ae85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./GenshinReview.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f0730da-a87e-41fb-92d8-81eb892d8ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>3</td>\n",
       "      <td>the games great overall but i always exit the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>5</td>\n",
       "      <td>an entertaining game with outstanding graphics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>5</td>\n",
       "      <td>play the game on my laptop and enjoy it there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>5</td>\n",
       "      <td>best mobile game ever existed days active eigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>5</td>\n",
       "      <td>i cannot describe how much i been loving this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>2</td>\n",
       "      <td>love it but it is a lot of grinding and i wish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>2</td>\n",
       "      <td>i give a stars because when i play it i do not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2</td>\n",
       "      <td>it just keep crashing even tho i have more tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>4</td>\n",
       "      <td>the game and story are amazing the graphics ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>5</td>\n",
       "      <td>this game is awesome i remember playing sword ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                                            content\n",
       "414       3  the games great overall but i always exit the ...\n",
       "1143      5  an entertaining game with outstanding graphics...\n",
       "1422      5  play the game on my laptop and enjoy it there ...\n",
       "1509      5  best mobile game ever existed days active eigh...\n",
       "1461      5  i cannot describe how much i been loving this ...\n",
       "575       2  love it but it is a lot of grinding and i wish...\n",
       "906       2  i give a stars because when i play it i do not...\n",
       "127       2  it just keep crashing even tho i have more tha...\n",
       "1340      4  the game and story are amazing the graphics ar...\n",
       "337       5  this game is awesome i remember playing sword ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87e3612a-cbcb-43b2-93a3-30ae7f3f5956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>the game is great audio background etc are all...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>the world building characters art design and g...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>this game is fun but at the time that fontaine...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>this game is beautiful and the game is very fu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>lost on furina banner but all together it is a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>after years of waiting still no controller sup...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>i love genshin but there is only one problem a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>awesome graphics if your phone can handle and ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>i do not know what is happening but when i cli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>the story is at peak level and not to mention ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>ngl games great but my storage cannot keep up ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>this is a very interesting and long term story...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>the games a very beautiful and the story and l...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>it is amazing and it does have a weird fandom ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>i soooooo love the game i played it since twen...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>the game is heavy if your using phone when pla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>i hate it when the screen turns black and i ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>giving this game a four stars instead of five ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>this game is very good they are very generous ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>so the game is great and all i was playing the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    score                                            content  sentiment\n",
       "0       5  the game is great audio background etc are all...          2\n",
       "1       4  the world building characters art design and g...          2\n",
       "2       4  this game is fun but at the time that fontaine...          2\n",
       "3       4  this game is beautiful and the game is very fu...          2\n",
       "4       4  lost on furina banner but all together it is a...          2\n",
       "5       1  after years of waiting still no controller sup...          0\n",
       "6       4  i love genshin but there is only one problem a...          2\n",
       "7       4  awesome graphics if your phone can handle and ...          2\n",
       "8       1  i do not know what is happening but when i cli...          0\n",
       "9       5  the story is at peak level and not to mention ...          2\n",
       "10      3  ngl games great but my storage cannot keep up ...          1\n",
       "11      5  this is a very interesting and long term story...          2\n",
       "12      5  the games a very beautiful and the story and l...          2\n",
       "13      5  it is amazing and it does have a weird fandom ...          2\n",
       "14      5  i soooooo love the game i played it since twen...          2\n",
       "15      3  the game is heavy if your using phone when pla...          1\n",
       "16      1  i hate it when the screen turns black and i ha...          0\n",
       "17      4  giving this game a four stars instead of five ...          2\n",
       "18      4  this game is very good they are very generous ...          2\n",
       "19      2  so the game is great and all i was playing the...          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating label called sentiment from the score reviews\n",
    "#1-2: negative\n",
    "#3: neutral\n",
    "#4-5: positive\n",
    "\n",
    "def map_rating_to_sentiment(rating):\n",
    "    if rating in [1, 2]:\n",
    "        return 0\n",
    "    elif rating == 3:\n",
    "        return 1\n",
    "    elif rating in [4, 5]:\n",
    "        return 2\n",
    "\n",
    "df['sentiment'] = df['score'].apply(map_rating_to_sentiment)\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6118939-b00a-48c9-9b01-b3baa5187b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#for now we have 2000 rows of reviews. we'll add more data perhaps later if the accuracy is still bad.\n",
    "x = df.sentiment.value_counts()\n",
    "sns.barplot(x=x.index, y=x)\n",
    "plt.gca().set_ylabel('reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c82d19b5-ca60-478b-8520-31424da41efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df.content.values\n",
    "labels = df.sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f0f76fb-cbf8-473b-8897-ee818ca96763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiffa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT Tokenizer\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "#using pr etrained bert tokenizer\n",
    "print(\"Loading BERT Tokenizer\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "710c3f7e-f67b-4acd-b6c0-a877ae628f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  the game is great audio background etc are all great but one thing i do not like is the wish system i do not have a five star character all i have got are four star character so it is suck to be a free to play unless you save a lot or primogems one good thing about it is you do not need a five star character to beat and enjoy the game though i do need the mc though as she can upgrade her constellations with just lvling up rank or the story progress yeah it is hard to earn primogems i guess i better sucked it up\n",
      "Tokenized:  ['the', 'game', 'is', 'great', 'audio', 'background', 'etc', 'are', 'all', 'great', 'but', 'one', 'thing', 'i', 'do', 'not', 'like', 'is', 'the', 'wish', 'system', 'i', 'do', 'not', 'have', 'a', 'five', 'star', 'character', 'all', 'i', 'have', 'got', 'are', 'four', 'star', 'character', 'so', 'it', 'is', 'suck', 'to', 'be', 'a', 'free', 'to', 'play', 'unless', 'you', 'save', 'a', 'lot', 'or', 'primo', '##gem', '##s', 'one', 'good', 'thing', 'about', 'it', 'is', 'you', 'do', 'not', 'need', 'a', 'five', 'star', 'character', 'to', 'beat', 'and', 'enjoy', 'the', 'game', 'though', 'i', 'do', 'need', 'the', 'mc', 'though', 'as', 'she', 'can', 'upgrade', 'her', 'constellation', '##s', 'with', 'just', 'lv', '##ling', 'up', 'rank', 'or', 'the', 'story', 'progress', 'yeah', 'it', 'is', 'hard', 'to', 'earn', 'primo', '##gem', '##s', 'i', 'gu', '##ess', 'i', 'better', 'suck', '##ed', 'it', 'up']\n",
      "Token IDS:  [10103, 11336, 10127, 11838, 18160, 23158, 12575, 10320, 10367, 11838, 10502, 10399, 21973, 151, 10154, 10497, 11531, 10127, 10103, 33020, 10472, 151, 10154, 10497, 10574, 143, 12049, 11424, 14989, 10367, 151, 10574, 15517, 10320, 11443, 11424, 14989, 10297, 10197, 10127, 59299, 10114, 10346, 143, 12487, 10114, 11923, 53804, 10855, 21343, 143, 15632, 10362, 12195, 21538, 10107, 10399, 12050, 21973, 10935, 10197, 10127, 10855, 10154, 10497, 15415, 143, 12049, 11424, 14989, 10114, 18477, 10110, 61530, 10103, 11336, 14325, 151, 10154, 15415, 10103, 22194, 14325, 10146, 10572, 10743, 82684, 10483, 65073, 10107, 10171, 12125, 74157, 12024, 10700, 24690, 10362, 10103, 12159, 22777, 82600, 10197, 10127, 15282, 10114, 59652, 12195, 21538, 10107, 151, 41567, 22523, 151, 16197, 59299, 10390, 10197, 10700]\n"
     ]
    }
   ],
   "source": [
    "print(\"Original: \", sentences[0])\n",
    "#yes it's not perfect, game word terms like primogems are not identified as english word.\n",
    "print(\"Tokenized: \", tokenizer.tokenize(sentences[0]))\n",
    "#tokenization time\n",
    "print(\"Token IDS: \", tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c987ea87-1ae2-4cd4-a3e7-74d8f3a448dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  the game is great audio background etc are all great but one thing i do not like is the wish system i do not have a five star character all i have got are four star character so it is suck to be a free to play unless you save a lot or primogems one good thing about it is you do not need a five star character to beat and enjoy the game though i do need the mc though as she can upgrade her constellations with just lvling up rank or the story progress yeah it is hard to earn primogems i guess i better sucked it up\n",
      "Token IDs:  [101, 10103, 11336, 10127, 11838, 18160, 23158, 12575, 10320, 10367, 11838, 10502, 10399, 21973, 151, 10154, 10497, 11531, 10127, 10103, 33020, 10472, 151, 10154, 10497, 10574, 143, 12049, 11424, 14989, 10367, 151, 10574, 15517, 10320, 11443, 11424, 14989, 10297, 10197, 10127, 59299, 10114, 10346, 143, 12487, 10114, 11923, 53804, 10855, 21343, 143, 15632, 10362, 12195, 21538, 10107, 10399, 12050, 21973, 10935, 10197, 10127, 10855, 10154, 10497, 15415, 143, 12049, 11424, 14989, 10114, 18477, 10110, 61530, 10103, 11336, 14325, 151, 10154, 15415, 10103, 22194, 14325, 10146, 10572, 10743, 82684, 10483, 65073, 10107, 10171, 12125, 74157, 12024, 10700, 24690, 10362, 10103, 12159, 22777, 82600, 10197, 10127, 15282, 10114, 59652, 12195, 21538, 10107, 151, 41567, 22523, 151, 16197, 59299, 10390, 10197, 10700, 102]\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "\n",
    "for sent in sentences:\n",
    "  encoded_sent = tokenizer.encode(\n",
    "      sent,\n",
    "      add_special_tokens = True\n",
    "  )\n",
    "  input_ids.append(encoded_sent)\n",
    "\n",
    "print(\"Original: \", sentences[0])\n",
    "print(\"Token IDs: \", input_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32880d3d-c569-4ddf-b396-591da9209d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  267\n"
     ]
    }
   ],
   "source": [
    "print(\"Max sentence length: \", max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48350909-3a6c-4beb-8ea4-ac95f76df530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tiffa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Padding/truncating all sentences to 64 values\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_LEN = 64\n",
    "\n",
    "print(\"Padding/truncating all sentences to %d values\" % MAX_LEN)\n",
    "print('Padding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype='long', value=0, truncating='post', padding='post')\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7556e2be-6b91-4a8b-9bd0-7625be11f18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101, 10103, 11336, 10127, 11838, 18160, 23158, 12575, 10320,\n",
       "       10367, 11838, 10502, 10399, 21973,   151, 10154, 10497, 11531,\n",
       "       10127, 10103, 33020, 10472,   151, 10154, 10497, 10574,   143,\n",
       "       12049, 11424, 14989, 10367,   151, 10574, 15517, 10320, 11443,\n",
       "       11424, 14989, 10297, 10197, 10127, 59299, 10114, 10346,   143,\n",
       "       12487, 10114, 11923, 53804, 10855, 21343,   143, 15632, 10362,\n",
       "       12195, 21538, 10107, 10399, 12050, 21973, 10935, 10197, 10127,\n",
       "       10855])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a21e22b7-db63-41f8-80a4-6a74471808fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = []\n",
    "\n",
    "for sent in input_ids:\n",
    "  att_mask = [int(token_id > 0) for token_id in sent]\n",
    "\n",
    "  attention_mask.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a962323b-f6f3-4760-9043-1492dc8fa3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_labels, test_labels = train_test_split(input_ids,labels, random_state=42, test_size=0.1)\n",
    "train_mask, test_mask, _, _ = train_test_split(attention_mask, labels, random_state=42, test_size=0.1)\n",
    "\n",
    "train_input, validation_input, train_labels, validation_labels = train_test_split(train_input, train_labels, random_state= 43, test_size=0.15)\n",
    "train_mask, validation_mask, _, _ = train_test_split(train_mask, train_mask, random_state=43, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "936bbcbf-b091-4cd5-bc32-d01a7d5177e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Train ==\n",
      "Input:  (1530, 64)\n",
      "Label:  (1530,)\n",
      "Mask:  (1530, 64)\n",
      "\n",
      "== Validation ==\n",
      "Input:  (270, 64)\n",
      "Label:  (270,)\n",
      "Mask:  (270, 64)\n",
      "\n",
      "== Test ==\n",
      "Input:  (200, 64)\n",
      "Label:  (200,)\n",
      "Mask:  (200, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"== Train ==\")\n",
    "print(\"Input: \", train_input.shape)\n",
    "print(\"Label: \", train_labels.shape)\n",
    "print(\"Mask: \", np.array(train_mask).shape)\n",
    "\n",
    "print(\"\\n== Validation ==\")\n",
    "print(\"Input: \", validation_input.shape)\n",
    "print(\"Label: \", validation_labels.shape)\n",
    "print(\"Mask: \", np.array(validation_mask).shape)\n",
    "\n",
    "print(\"\\n== Test ==\")\n",
    "print(\"Input: \", test_input.shape)\n",
    "print(\"Label: \", test_labels.shape)\n",
    "print(\"Mask: \", np.array(test_mask).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0021144-8963-4966-9e73-a4718736bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = torch.tensor(train_input)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_mask = torch.tensor(train_mask)\n",
    "\n",
    "validation_input = torch.tensor(validation_input)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_mask = torch.tensor(validation_mask)\n",
    "\n",
    "test_input = torch.tensor(test_input)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "test_mask = torch.tensor(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9039a566-da1d-4266-9007-00515a0ef8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_data = TensorDataset(train_input, train_mask, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_input, validation_mask, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(test_input, test_mask, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7de96595-35fb-45c5-b035-9a34866e6c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-uncased\",\n",
    "    num_labels = 3,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    ")\n",
    "\n",
    "#Assuming you have labeled training data (train_dataset) and an optimizer (optimizer)\n",
    "# from transformers import BertTokenizer, BertForSequenceClassification\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "#Load tokenizer and model\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "# model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-uncased\", num_labels=3)\n",
    "\n",
    "#Fine-tune the model\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#for epoch in range(num_epochs):\n",
    "#     for batch in train_dataloader:\n",
    "#         inputs = tokenizer(batch[\"text\"], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "#         labels = batch[\"labels\"]\n",
    "\n",
    "#         outputs = model(**inputs, labels=labels)\n",
    "#         loss = outputs.loss\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#Save the fine-tuned model for later use\n",
    "# model.save_pretrained(\"fine_tuned_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "944da474-e6a2-4bf3-bdc3-9587f05ee1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "==== Embedding Layer ====\n",
      "bert.embeddings.word_embeddings.weight                       (105879, 768)\n",
      "bert.embeddings.position_embeddings.weight                     (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                     (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                                   (768,)\n",
      "bert.embeddings.LayerNorm.bias                                     (768,)\n",
      "==== First Transformers ====\n",
      "bert.encoder.layer.0.attention.self.query.weight               (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                     (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight                 (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                       (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight               (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                     (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight             (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias                   (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight             (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias               (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight                (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                      (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                      (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                             (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                       (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                         (768,)\n",
      "==== Output Layer ====\n",
      "bert.pooler.dense.weight                                       (768, 768)\n",
      "bert.pooler.dense.bias                                             (768,)\n",
      "classifier.weight                                                (3, 768)\n",
      "classifier.bias                                                      (3,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "\n",
    "print(\"The BERT model has {:} different named parameters.\".format(len(params)))\n",
    "\n",
    "print(\"==== Embedding Layer ====\")\n",
    "for p in params[0:5]:\n",
    "  print(\"{:<60} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print(\"==== First Transformers ====\")\n",
    "for p in params[5:21]:\n",
    "  print(\"{:<60} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print(\"==== Output Layer ====\")\n",
    "for p in params[-4:]:\n",
    "  print(\"{:<60} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c6481e3-56af-4cc0-93ad-0387207048a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiffa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 2e-5,\n",
    "    eps = 1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dbefe2a-27e8-4afe-aa37-c1d6dc6a26be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "261b2888-3dd6-453c-91b0-a4ba17a1cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "  labels_flat = labels.flatten()\n",
    "  return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07e9684b-db8d-4294-b143-b5581e40e63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "  elapsed_rounded = int(round(elapsed))\n",
    "  return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b87a3-5279-4ec8-a30c-be075447da17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Epoch 1 / 10 =======\n",
      "Training...\n",
      "Batch    40 of    48.     Elapsed: 0:09:42\n",
      "   Average training loss: 0.80\n",
      "   Training epoch took: 0:11:39\n",
      "Running Validation...\n",
      "   Accuracy: 0.77\n",
      "   Validation took: 0:00:41\n",
      "======= Epoch 2 / 10 =======\n",
      "Training...\n",
      "Batch    40 of    48.     Elapsed: 0:09:39\n",
      "   Average training loss: 0.69\n",
      "   Training epoch took: 0:11:32\n",
      "Running Validation...\n",
      "   Accuracy: 0.77\n",
      "   Validation took: 0:00:39\n",
      "======= Epoch 3 / 10 =======\n",
      "Training...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "#Training time\n",
    "  print(\"======= Epoch {:} / {:} =======\".format(epoch_i+1, epochs))\n",
    "  print(\"Training...\")\n",
    "\n",
    "  t0 = time.time()\n",
    "\n",
    "  total_loss = 0\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  # For each batch of training data\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # Progress update every 40 batches\n",
    "    if step % 40 == 0 and not step == 0:\n",
    "      elapsed = format_time(time.time() - t0)\n",
    "\n",
    "      print(\"Batch {:>5,} of {:>5,}.     Elapsed: {:}\".format(step, len(train_dataloader), elapsed))\n",
    "    \n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    outputs = model(b_input_ids,\n",
    "                    token_type_ids=None,\n",
    "                    attention_mask=b_input_mask,\n",
    "                    labels=b_labels)\n",
    "    \n",
    "    loss = outputs[0]\n",
    "    total_loss += loss.item()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "  avg_train_loss = total_loss / len(train_dataloader)\n",
    "  loss_values.append(avg_train_loss)\n",
    "\n",
    "  print(\"   Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "  print(\"   Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "#validation time\n",
    "  print(\"Running Validation...\")\n",
    "  t0 = time.time()\n",
    "  model.eval()\n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "  for batch in validation_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    with torch.no_grad():\n",
    "      outputs = model(b_input_ids,\n",
    "                      token_type_ids=None,\n",
    "                      attention_mask=b_input_mask)\n",
    "    \n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "  \n",
    "  print(\"   Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "  print(\"   Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d472d9-925a-4792-bb0d-81bd51156fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "#plotting will be continued once this thing is done training bro\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf3aa0-533d-48c2-8885-d7e4ff3fe532",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting labels for {:,} test sentences\".format(len(test_input)))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "prediction, true_labels = [], []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "  with torch.no_grad():\n",
    "    outputs = model(b_input_ids,\n",
    "                    token_type_ids=None,\n",
    "                    attention_mask=b_input_mask)\n",
    "    \n",
    "  logits = outputs[0]\n",
    "\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "  prediction.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print(\"finally??? done!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d2b184-a127-48d1-a1c3-7010007a1d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "flat_prediction = [item for sublist in prediction for item in sublist]\n",
    "flat_prediction = np.argmax(flat_prediction, axis=1).flatten()\n",
    "\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_prediction)\n",
    "\n",
    "print(\"MATTHEWS_CC: %.3f\" %mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee24d964-18ec-4170-af23-59842b5f23f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(flat_true_labels, flat_prediction)\n",
    "\n",
    "print(\"ACCURACY: %.3f\" %acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
